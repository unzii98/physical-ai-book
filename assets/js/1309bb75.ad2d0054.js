"use strict";(globalThis.webpackChunkbook=globalThis.webpackChunkbook||[]).push([[558],{1027:(i,n,e)=>{e.r(n),e.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"digital-twin-sim/unity-hri","title":"High-Fidelity Rendering in Unity","description":"While Gazebo excels at physics, Unity (a game engine) is increasingly used in robotics for its superior visual fidelity and interactive capabilities, especially for Human-Robot Interaction (HRI) scenarios.","source":"@site/docs/02-digital-twin-sim/02-unity-hri.md","sourceDirName":"02-digital-twin-sim","slug":"/digital-twin-sim/unity-hri","permalink":"/physical-ai-book/docs/digital-twin-sim/unity-hri","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Physics, Gravity, and Collisions in Gazebo","permalink":"/physical-ai-book/docs/digital-twin-sim/gazebo-physics"},"next":{"title":"Simulating Sensors: LiDAR, Depth, and IMU","permalink":"/physical-ai-book/docs/digital-twin-sim/simulating-sensors"}}');var s=e(4848),o=e(8453);const r={sidebar_position:2},a="High-Fidelity Rendering in Unity",l={},c=[{value:"Why Unity for Robotics?",id:"why-unity-for-robotics",level:2},{value:"Unity Robotics Hub",id:"unity-robotics-hub",level:2},{value:"Human-Robot Interaction (HRI)",id:"human-robot-interaction-hri",level:2}];function d(i){const n={h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...i.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"high-fidelity-rendering-in-unity",children:"High-Fidelity Rendering in Unity"})}),"\n",(0,s.jsx)(n.p,{children:"While Gazebo excels at physics, Unity (a game engine) is increasingly used in robotics for its superior visual fidelity and interactive capabilities, especially for Human-Robot Interaction (HRI) scenarios."}),"\n",(0,s.jsx)(n.h2,{id:"why-unity-for-robotics",children:"Why Unity for Robotics?"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Photorealism"}),": Unity's High Definition Render Pipeline (HDRP) enables realistic lighting, shadows, and textures. This is crucial for training computer vision models that need to generalize to the real world."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Performance"}),": optimized for real-time rendering of complex scenes at high frame rates."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Asset Store"}),": Access to a massive library of 3D environments (homes, offices, cities) to test robots in diverse settings."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"unity-robotics-hub",children:"Unity Robotics Hub"}),"\n",(0,s.jsxs)(n.p,{children:["Unity provides the ",(0,s.jsx)(n.strong,{children:"Unity Robotics Hub"}),", a set of tools to bridge Unity with ROS 2:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"URDF Importer"}),": Automatically converts your robot's URDF into Unity GameObjects with ArticulationBodies (Unity's physics components for robots)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"ROS-TCP-Connector"}),": Establishes communication between Unity (C#) and ROS 2 (Python/C++)."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"human-robot-interaction-hri",children:"Human-Robot Interaction (HRI)"}),"\n",(0,s.jsx)(n.p,{children:"Unity is ideal for HRI because you can easily script complex human behaviors using animations and AI navigation meshes."}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Scenario"}),": A robot navigating a crowded hallway."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simulation"}),": In Unity, you can spawn dozens of human characters walking with realistic gaits and collision avoidance, testing if your robot can safely navigate around them."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:'This "Sim-to-Real" gap is significantly reduced when the visual input to the robot\'s cameras in simulation closely matches the physical world.'})]})}function h(i={}){const{wrapper:n}={...(0,o.R)(),...i.components};return n?(0,s.jsx)(n,{...i,children:(0,s.jsx)(d,{...i})}):d(i)}},8453:(i,n,e)=>{e.d(n,{R:()=>r,x:()=>a});var t=e(6540);const s={},o=t.createContext(s);function r(i){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof i?i(n):{...n,...i}},[n,i])}function a(i){let n;return n=i.disableParentContext?"function"==typeof i.components?i.components(s):i.components||s:r(i.components),t.createElement(o.Provider,{value:n},i.children)}}}]);